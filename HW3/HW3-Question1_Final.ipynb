{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">EE 461P: Data Science Principles</p>\n",
    "# <p style=\"text-align: center;\">Assignment 3</p>\n",
    "## <p style=\"text-align: center;\">Total points: 75</p>\n",
    "## <p style=\"text-align: center;\">Due: Thursday, October 25th, submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  **Please include the name and UTEID for both students on all submitted files (including this notebook).** In addition, please convert **your filename including your EID** (ex. ss324.jpynb or ss324_mj345.jpypb).\n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1a - Stochastic Gradient Descent (25pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (4pts) Using stochastic gradient descent, derive the coefficent updates for all 4 coefficients of the model: $$ y = w_0 + w_1x_1 + w_2x_1^2 + w_3x_1x_2 $$ Hint: start from the cost function (Assume sum of squared error). If you write the math by hand, include the image in your notebook.\n",
    "\n",
    "\n",
    "2. (12pts) Write Python code for an SGD solution to the non-linear model $$ y = w_0 + w_1x_1 + w_2x_1^2 + w_3x_1x_2$$ Try to format similarly to scikit-learn's models. Your class should take as input the learning_rate, regularization_constant and number of epochs. The fit method must take as input X,y and a choice of update_rule as 'sgd' or 'sgd_momentum' or 'rmsprop'(Notes on implementation below). The _predict_ method takes an X value (optionally, an array of values). Use your new gradient descent regression to predict the data given in 'samples.csv', for 15 epochs, using learning rates: [.0001, .001, .01, 0.1, 1, 10, 100] and regularization constants in the range: [0,10,100] . Plot MSE and the $w$ parameters as a function of epoch (for 15 epochs) for the best 2 combinations of learning_rate and regularization for SGD, SGD-Momentum and RMSProp. I.e., you should have one plot of MSE and another for the parameter updates for SGD, SGD-Momentum and RMSProp (6 plots total).\n",
    "\n",
    "\n",
    "4. (2pts) Report the MSE at the end of 15 epochs for both combinations.\n",
    "\n",
    "\n",
    "5. (3pts) Based on the experiments, which of the 3 techniques allowed for larger initial setting of the learning_rate? Why?\n",
    "\n",
    "\n",
    "6. Now consider the following 2x2x1 network with one hidden layer. The input layer has two nodes, and the output layer has one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 only working with training data, predict training data, and fit on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 It is RMS PROP because the learning rate is adaptive, and decreases as the number of iterations increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUST CORRECT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUST CORRECT BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUST CORRECT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wo(t+1) = wo(t) - learning_rate*(actual - wo(t)) * 2\n",
    "#w1(t+1) = w1(t) - learning_rate*(actual - w1(t)*x1) * x1 * 2\n",
    "#w2(t+1) = w2(t) - learning_rate*(actual - w2(t)*x1^2) * x1^2 *2\n",
    "#w3(t+1) = w3(t) - learning_rate*(actual - w3(t)*x1*x2)*x1*x2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.697532</td>\n",
       "      <td>1.135251</td>\n",
       "      <td>-18.284819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.324355</td>\n",
       "      <td>1.042443</td>\n",
       "      <td>-0.251914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.982079</td>\n",
       "      <td>4.053857</td>\n",
       "      <td>-2.350819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.637966</td>\n",
       "      <td>4.107375</td>\n",
       "      <td>-2.831104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.359560</td>\n",
       "      <td>3.727414</td>\n",
       "      <td>-12.663515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        x1        x2          y\n",
       "0           0  4.697532  1.135251 -18.284819\n",
       "1           1 -0.324355  1.042443  -0.251914\n",
       "2           2 -0.982079  4.053857  -2.350819\n",
       "3           3  2.637966  4.107375  -2.831104\n",
       "4           4  4.359560  3.727414 -12.663515"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv('samples.csv')\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samples.iloc[:,1:3]\n",
    "y = samples.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "learning_rates = [.0001, .001, .01, 0.1, 1, 10, 100]\n",
    "reg_constants = [0,10,100] \n",
    "num_epochs = 15\n",
    "#sgd_regressor = SGDRegressor(learning_rates,reg_consts,num_epochs)\n",
    "#coefs = sgd_regressor.fit(X,y,'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    def __init__(self,learning_rate,regularization_constant,number_of_epochs):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.number_of_epochs = number_of_epochs\n",
    "        self.w = np.zeros(4)\n",
    "        self.v = np.zeros(4)\n",
    "        self.cache = np.zeros(4)\n",
    "        self.decay_rate = 0.9\n",
    "    def fit(self,X,y,update_rule):\n",
    "        gradient = np.zeros(4)\n",
    "        actual = 0\n",
    "        predicted = 0\n",
    "        #print('initialize done')\n",
    "        \n",
    "        for j in range(0,self.number_of_epochs):\n",
    "            for i in range(0,X.shape[0]):\n",
    "                actual = y[i]\n",
    "                #print('Actual: ' + str(actual))\n",
    "                point = X.iloc[i:i+1,:]\n",
    "                x1 = point.iloc[0,0]\n",
    "                x2 = point.iloc[0,1]\n",
    "                #print('X1= ' + str(x1) + ' X2= ' + str(x2))\n",
    "                predicted = self.w[0] + self.w[1]*x1 + self.w[2]*x1**2 + self.w[3]*x1*x2\n",
    "\n",
    "                error = predicted - actual\n",
    "                #removed lambda regularizer failed when set to 0\n",
    "                #print('Error: ' + str(error))\n",
    "                gradient[0] = 2*(error) \n",
    "                gradient[1] = 2*(error*x1)\n",
    "                gradient[2] = 2*(error*x1**2)\n",
    "                gradient[3] = 2*(error*x1*x2)\n",
    "                \n",
    "                \n",
    "                #print('Gradient: ' + str(gradient))\n",
    "                #update the coefficients \n",
    "                if update_rule == 'SGD':\n",
    "                    #print('Weights: ' + str(self.w))\n",
    "                    self.w[0] = self.w[0] - self.learning_rate*gradient[0]  \n",
    "                    self.w[1] = self.w[1] - self.learning_rate*gradient[1]\n",
    "                    self.w[2] = self.w[2] - self.learning_rate*gradient[2]\n",
    "                    self.w[3] = self.w[3] - self.learning_rate*gradient[3]\n",
    "                elif update_rule == 'SGD-Momentum':\n",
    "                    self.v[0] = self.v[0] - self.learning_rate*gradient[0] \n",
    "                    self.v[1] = self.v[1] - self.learning_rate*gradient[1]  \n",
    "                    self.v[2] = self.v[2] - self.learning_rate*gradient[2]\n",
    "                    self.v[3] = self.v[3] - self.learning_rate*gradient[3]  \n",
    "\n",
    "                    self.w += self.v\n",
    "                else:\n",
    "                    for i in range(0,4):\n",
    "                        self.cache[i] = (0.9)*(self.cache[i]) + (0.1)*(gradient[i]**2)\n",
    "                    \n",
    "                    self.w[0] = self.w[0] - (self.learning_rate)/(np.sqrt(self.cache[0] + 1.1e-6))*gradient[0]\n",
    "                    self.w[1] = self.w[1] - (self.learning_rate)/(np.sqrt(self.cache[1] + 1.1e-6))*gradient[1]\n",
    "                    self.w[2] = self.w[2] - (self.learning_rate)/(np.sqrt(self.cache[2] + 1.1e-6))*gradient[2]\n",
    "                    self.w[3] = self.w[3] - (self.learning_rate)/(np.sqrt(self.cache[3] + 1.1e-6))*gradient[3]\n",
    "                    \n",
    "\n",
    "\n",
    "#weights = weights - ((learning_rate)/sqrt(cache+1e-6))*gradients\n",
    "#Use decay_rate = 0.90. Initialize cache with zeros.\n",
    "                    \n",
    "                #print('Done with iteration: ' + str(i))\n",
    "            #print('Done with epoch: ' + str(j))\n",
    "            #for i in range(0,len(self.w)):\n",
    "                #print('Coefficient: ' + str(i) + ' ' + str(self.w[i]))\n",
    "                \n",
    "    def predict(self,X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        for i in range(0,X.shape[0]):\n",
    "            point = X.iloc[i:i+1,:]\n",
    "            x1 = point.iloc[0,0]\n",
    "            x2 = point.iloc[0,1]\n",
    "            predicted = self.w[0] + self.w[1]*x1 + self.w[2]*x1**2 + self.w[3]*x1*x2\n",
    "            y[i] = predicted\n",
    "            \n",
    "        return y                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Index: 0\n",
      "14.287803558583805\n",
      "3.6828851298570213\n",
      "1.6382188803905726\n",
      "1.037556218546273\n",
      "0.7996363920599546\n",
      "0.6826399773863904\n",
      "0.6119513575591963\n",
      "0.5607032708375411\n",
      "0.5186252634278303\n",
      "0.4816563689538011\n",
      "0.44811889886535833\n",
      "0.41726141978008835\n",
      "0.3886976653603892\n",
      "0.36218938091979125\n",
      "0.3375618808619169\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Index: 1\n",
      "0.8101275745729194\n",
      "0.3577733858567549\n",
      "0.1591941234206756\n",
      "0.07280997903554008\n",
      "0.03512925567227984\n",
      "0.018560376473032596\n",
      "0.011132046712699436\n",
      "0.007660619227106689\n",
      "0.005907416341851375\n",
      "0.004908721780282663\n",
      "0.004251102181957096\n",
      "0.003757624883906936\n",
      "0.003352414927379974\n",
      "0.003002452859519114\n",
      "0.002692724650811369\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Index: 2\n",
      "5.073075608082219e+18\n",
      "3.393539847698858e+35\n",
      "2.2700455472205374e+52\n",
      "1.5185048703494921e+69\n",
      "1.015775672033736e+86\n",
      "6.794842980372603e+102\n",
      "4.545284199953311e+119\n",
      "3.040483572324184e+136\n",
      "2.0338750993102205e+153\n",
      "1.3605230290496327e+170\n",
      "9.100966491020787e+186\n",
      "6.0879227548644566e+203\n",
      "4.0724030250812554e+220\n",
      "2.7241584800726097e+237\n",
      "1.8222752951627238e+254\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NikhilGaur\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py:239: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "C:\\Users\\NikhilGaur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in double_scalars\n",
      "C:\\Users\\NikhilGaur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\NikhilGaur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0eb5733a6e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mcoefficient_all_models_epochs_sgd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mmse_sgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0mmean_squared_error_all_models_epochs_sgd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse_sgd\u001b[0m \u001b[1;31m#k is actually model num\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mfinal_mse_all_models_sgd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse_sgd\u001b[0m \u001b[1;31m#keep track of final mse for all models\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 238\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[0;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#loop over all regularization constants\n",
    "coefficient_all_models_epochs_sgd = np.zeros(shape = (21,15,4))\n",
    "coefficient_all_models_epochs_sgd_momentum_regressor = np.zeros(shape = (21,15,4))\n",
    "coefficient_all_models_epochs_sgd_rms_props = np.zeros(shape = (21,15,4))\n",
    "mean_squared_error_all_models_epochs_sgd = np.zeros(shape = (21,15))\n",
    "mean_squared_error_all_models_epochs_sgd_momentum = np.zeros(shape = (21,15))\n",
    "mean_squared_error_all_models_epochs_sgd_rms_props = np.zeros(shape = (21,15))\n",
    "mse_sgd = 0\n",
    "mse_sgd_momentum = 0\n",
    "model_index = 0\n",
    "final_mse_all_models_sgd = np.zeros(21)\n",
    "final_mse_all_models_sgd_momentum = np.zeros(21)\n",
    "final_mse_all_models_sgd_momentum_rms_prop = np.zeros(21)\n",
    "sgd_learning_rates = np.zeros(21)\n",
    "sgd_momentum_learning_rates = np.zeros(21)\n",
    "sgd_reg_consts = np.zeros(21)\n",
    "#epoch_num = 0\n",
    "\n",
    "for reg_const in reg_constants:\n",
    "    #print('Reg Const: ' + str(reg_const))\n",
    "    for learning_rate in learning_rates:\n",
    "        sgd_regressor = SGDRegressor(learning_rate,reg_const,1)\n",
    "        #print('Learning Rate: ' + str(learning_rate))\n",
    "\n",
    "        for epoch_num in range(0,num_epochs):\n",
    "            mse_sgd = 0\n",
    "            sgd_regressor.fit(X,y,'SGD')\n",
    "            #print('Model Index: ' + str(model_index) + ' Epoch Number: ' + str(epoch_num))\n",
    "\n",
    "            for coef in range(0,coefficient_all_models_epochs_sgd.shape[2]):\n",
    "                #print('Coefficient: ' + str(i) + ' ' + str(sgd_regressor.w[i]))\n",
    "                coefficient_all_models_epochs_sgd[model_index][epoch_num][coef] = sgd_regressor.w[coef]\n",
    "            y_pred = sgd_regressor.predict(X)\n",
    "            mse_sgd = mean_squared_error(y,y_pred)\n",
    "            mean_squared_error_all_models_epochs_sgd[model_index][epoch_num] = mse_sgd #k is actually model num\n",
    "            final_mse_all_models_sgd[model_index] = mse_sgd #keep track of final mse for all models\n",
    "        print('Model Index: ' + str(model_index))\n",
    "        for epoch in range(0,15):\n",
    "            plt.scatter(epoch,mean_squared_error_all_models_epochs_sgd[model_index][epoch])\n",
    "            print(mean_squared_error_all_models_epochs_sgd[model_index][epoch])\n",
    "        plt.show()\n",
    "        #sgd_learning_rates[model_index] = learning_rate\n",
    "        #sgd_reg_consts[model_index] = reg_const\n",
    "        #print('Model Index: ' + str(model_index) + ' Final Coefficient Vector: ' + str(sgd_regressor.w))\n",
    "        #print('Learning Rate: ' + str(learning_rate) + 'Reg Const: ' + str(reg_const))\n",
    "        model_index+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Index: 1 Epoch Number: 14\n",
    "#Model Index: 1 Final Coefficient Vector: [ 0.02924744  0.4981523  -0.99470778  0.2490308 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate: 0.001Reg Const: 0\n",
    "#Learning Rate: 0.01\n",
    "#Gradient at Beginning of Model 3 (Index:2) Gradient: [ 36.56963831 171.78703654 806.97505595 195.02140303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(final_mse_all_models_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find best two models in regular sgd\n",
    "final_mse_all_models_sgd_sorted_indices = np.argsort(final_mse_all_models_sgd) \n",
    "smallest_mse_index = final_mse_all_models_sgd_sorted_indices[0]\n",
    "second_smallest_mse_index = final_mse_all_models_sgd_sorted_indices[1]\n",
    "#final_mse_all_models_sgd_sorted = np.sort(final_mse_all_models_sgd)\n",
    "#print(final_mse_all_models_sgd_sorted)\n",
    "# best_sgd_model_coefficients_per_epoch is array of arrays, it has the 15 epochs of the best sgd model, and the coefficients for\n",
    "#for all those epochs\n",
    "best_sgd_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd[smallest_mse_index]\n",
    "print('BEST MSE SGD: ' + str(final_mse_all_models_sgd[smallest_mse_index]))\n",
    "second_best_sgd_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd[second_smallest_mse_index]\n",
    "print('SECOND BEST MSE SGD: ' + str(final_mse_all_models_sgd[second_smallest_mse_index]))\n",
    "\n",
    "#gives list of coefficients at each epoch, indexing gets you coefficients\n",
    "\n",
    "#get coefficients and MSE for models based on epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,15):\n",
    "    epoch_coefficients = best_sgd_model_coefficients_per_epoch[epoch]\n",
    "    #print('Epoch Coefficients shape: ' + str(epoch_coefficients.shape))\n",
    "    print('Epoch: ' + str(epoch) + ' ' + str(epoch_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mse_all_models_sgd_momentum_sorted_indices = np.argsort(final_mse_all_models_sgd_momentum)\n",
    "smallest_mse_sgd_momentum_index = final_mse_all_models_sgd_momentum_sorted_indices[0]\n",
    "second_smallest_mse_sgd_momentum_index = final_mse_all_models_sgd_momentum_sorted_indices[1]\n",
    "best_sgd_momentum_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd_momentum_regressor[smallest_mse_sgd_momentum_index]\n",
    "print('BEST MSE SGD_MOMENTUM: ' + str(final_mse_all_models_sgd_momentum[smallest_mse_sgd_momentum_index]))\n",
    "second_best_sgd_momentum_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd_momentum_regressor[second_smallest_mse_sgd_momentum_index]\n",
    "print('SECOND BEST MSE SGD_MOMENTUM: ' + str(final_mse_all_models_sgd_momentum[second_smallest_mse_sgd_momentum_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mse_all_models_sgd_momentum_rms_prop_sorted_indices = np.argsort(final_mse_all_models_sgd_momentum_rms_prop)\n",
    "smallest_mse_rms_prop_index = final_mse_all_models_sgd_momentum_rms_prop_sorted_indices[0]\n",
    "second_smallest_mse_rms_prop_index = final_mse_all_models_sgd_momentum_rms_prop_sorted_indices[1]\n",
    "best_sgd_momentum_rms_prop_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd_rms_props[0]\n",
    "print('BEST MSE SGD_RMS_PROPS: ' + str(final_mse_all_models_sgd_momentum_rms_prop[smallest_mse_rms_prop_index]))\n",
    "second_best_sgd_momentum_rms_prop_model_coefficients_per_epoch = coefficient_all_models_epochs_sgd_rms_props[1] \n",
    "print('SECOND BEST MSE SGD_RMS_PROPS: ' + str(final_mse_all_models_sgd_momentum_rms_prop[second_smallest_mse_rms_prop_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(1,16))\n",
    "coefficients = list()\n",
    "ax = plt.gca()\n",
    "for epoch in range(0,15):\n",
    "    epoch_coefficients = best_sgd_model_coefficients_per_epoch[epoch]\n",
    "    #print('Epoch Coefficients shape: ' + str(epoch_coefficients.shape))\n",
    "    print('Epoch: ' + str(epoch) + ' ' + str(epoch_coefficients))\n",
    "    for coefficient in epoch_coefficients:\n",
    "        plt.scatter(epoch,coefficient)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef in sgd_regressor.w:\n",
    "    print('Coef: ' + str(coef))"
   ]
  },
  {
   "attachments": {
    "q1_networkdiagram.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![q1_networkdiagram.PNG](attachment:q1_networkdiagram.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both hidden layer units use a *sigmoid* activation function, and the output unit uses an identity activation (i.e. the output is just a weighted sum of the inputs).\n",
    "\n",
    "(a) (2pts) Write the output $y$ as a function of the inputs $x_1$ and $x_2$.\n",
    "\n",
    "(b) (2pts) Derive the update rule for the layer-one weight $w_{12}^{(1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAT IS WRONG WITH THE COEFFICIENTS REMOVE SGD_MOMENTUM CODE and RMS PROPS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(w11x1 + w21x2)*w1^(2) + (w12^(1)x1 + w22^(1)x2)*w2^(2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on SGD with momentum\n",
    "Momentum helps accelerate SGD in relevant direction and dampens the oscillations. It tries to maintain the direction in which the gradient vector was already pointing and adjusts the direction slowly with the new gradients. The steps can be listed below :\n",
    "1. v[t] = mu * v[t-1] - (learning_rate)*(gradient)\n",
    "2. w = w + v\n",
    "\n",
    "Set mu = 0.90. Initialize v with zeros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on RMSProp\n",
    "RMSProp (http://ruder.io/optimizing-gradient-descent/) differs from vanilla SGD in that the learning rate of each weight changes over updates. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate.  In particular, it uses a moving average of squared gradients as cache. The learning_rate is divided by the cache, resulting in a different learning rate for each weight. A consequence of this update rule is that weights that have already seen large gradients (made large jumps) make smaller updates in subsequent iterations.\n",
    "Specifically, the steps can be listed as below:\n",
    "1. cache = (decay_rate)*(cache) + (1 - decay_rate)*(gradients^2) \n",
    "2. weights = weights - ((learning_rate)/sqrt(cache+1e-6))*gradients\n",
    "\n",
    "Use decay_rate = 0.90. Initialize cache with zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Notes on Training with Gradient Descent\n",
    "1. Compute error: This consists of a prediction error and a regularization term. From an implementation perspective, this is a function that takes as input the truth, prediction and regularization hyperparameter and returns an error\n",
    "2. Compute gradients: Take a derivative of the error in terms of the weights. This can be modelled as a function that takes as input the error and features and returns the gradients for each weight\n",
    "3. Update weights: Weight updates can be done using vanilla SGD or adaptive techniques. The update function takes as inputs the gradient and hyperparameters and returns the new weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Multi-layer perceptron Regressor (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, you will explore the application of Multi-layer Perceptron (MLP) regression using sklearn package in Python;\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html.\n",
    "\n",
    "\n",
    "We will use the OpenCL gemm kernel performance prediction dataset for this problem; https://archive.ics.uci.edu/ml/datasets/SGEMM+GPU+kernel+performance.\n",
    "\n",
    "Following code will pre-process the data and split the data into training and test set using [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with **random state 30** and **test_size = 0.25**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to use in this problem is [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Instead of fitting a model on original data, use StandardScaler to make each feature centered ([Example](http://scikit-learn.org/stable/auto_examples/applications/plot_prediction_latency.html#sphx-glr-auto-examples-applications-plot-prediction-latency-py)). Whenever you have training and test data, fit a scaler on training data and use this scaler on test data. Here, scale only features (independent variables), not target variable y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) (5pts) Use [sklearn.neural_nework.MLPRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) to do a 5-fold cross validation using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold). The cross validation must be performed on the **training data**. Use following parameter settings for MLPRegressor:\n",
    "\n",
    "    activation = 'tanh', solver = 'sgd', learning_rate='constant', random_state=42,\n",
    "    batch_size=30, learning_rate_init = 0.005\n",
    "    \n",
    "Now, consider the following settings for the number of hidden units:\n",
    "    \n",
    "   (a) *hidden_layer_sizes = (2,)* \n",
    "   \n",
    "   (b) *hidden_layer_sizes = (10,)*\n",
    "   \n",
    "   (c) *hidden_layer_sizes = (30,)*\n",
    "   \n",
    "   (d) *hidden_layer_sizes = (50,)*\n",
    "   \n",
    "   Report the average Root Mean Squared Error (RMSE) value based on your 5-fold cross validation for each model.\n",
    "   \n",
    "   \n",
    "2) (5pts) Now, using the same parameters used in part 1), train MLPRegressor models on the entire training set and report the RMSE score for both the trainnig and testing sets (again, use StandardScaler). Which of the four models ((a)-(d)) performs the best? Briefly analyze and discuss the results, commenting on the number of hidden units.\n",
    "\n",
    "\n",
    "3) (5pts) MLPRegressor has a built-in attribute *loss\\_curve\\_* which returns the loss at each epoch (misleadingly referred to as \"iteration\" in scikit documentation, though they use epoch in the actual code!). For example, if your model is named as *my_model* you can call it as *my\\_model.loss\\_curve\\_* ([example](http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_training_curves.html#sphx-glr-auto-examples-neural-networks-plot-mlp-training-curves-py)). Plot three curves using below conditions (a, b, c) in one figure, where *X-axis* is epoch  number and *Y-axis* is squared root of *loss\\_curve\\_* valu;:\n",
    "\n",
    "   (a) *hidden_layer_sizes = (1,)* \n",
    "   \n",
    "   (b) *hidden_layer_sizes = (5,)*\n",
    "   \n",
    "   (c) *hidden_layer_sizes = (10,)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - [Kaggle Competition] Nomad2018 Predicting Transparent Conductors (25 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we are going to explore a Kaggle competition: [Transparent Conductors](https://www.kaggle.com/c/nomad2018-predict-transparent-conductors). Your goal is to obtain the best score you can in this competition.\n",
    "\n",
    "The first step is to make a Kaggle account. Then find this competition and read the competition details and the description of the dataset. \n",
    "\n",
    "Your work should meet the following requirements:\n",
    "\n",
    "1. Data Preprocessing. \n",
    " * Conduct some data preprocessing. (Hint: see if there is any skewed features and consider applying suitable transformation techniques to make them more \"normal\").\n",
    " * Impute the missing values (if any).\n",
    " * Create new features using interactions\n",
    "2. Predictive Models. \n",
    " * You have to create three models: Lasso regression, Ridge regression, and multilayer perceptron.  For Lasso and Ridge regression, optimize the alphas using cross validation. For the MLP model, you can use one hidden layer. You may try other predictive models to get better scores (optional).\n",
    "3. Get a score of 0.0800 or lower on the Private Leaderboard. Take a screenshot of your private leaderboard after submission as proof. You can also click My Submissions tab to see the history of your submissions. It will show both Public Leaderboard & Private Leaderboard score.\n",
    "\n",
    "Briefly describe your work on each of these steps. Explain (very briefly) what approaches you tried, what worked and what did not work. Mention your team's kaggle name and include a screen shot of your public submission score. Finally, try your best to win this competition!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
